```mdx
---
title: AI Services Integration
description: OpenAI and Anthropic integration for Task Breakdown in Task Dojo
---

Overview

Task Dojo integrates AI services for the AI Feat Breakdown feature, which helps users decompose complex tasks into manageable subtasks.

Supported Providers:
OpenAI (GPT-4) - Default, high quality
Anthropic (Claude 3) - Alternative, cost-effective

<Info>
AI services are optional. Task Dojo works fully without them, users just can't use the AI Feat Breakdown feature.
</Info>

---

Setup

1. Choose AI Provider

Pick one provider (or configure both for redundancy):

<Tabs>
  <Tab title="OpenAI (Recommended)">
    Best for: High-quality, detailed task breakdowns
    
    Pricing: ~$0.03 per breakdown request
    
    Model: GPT-4-turbo
    
Go to platform.openai.com
Sign up / log in
Navigate to API Keys
Create new secret key
Copy key (starts with `sk-...`)
  </Tab>

  <Tab title="Anthropic">
    Best for: Cost-effective, fast responses
    
    Pricing: ~$0.015 per breakdown request
    
    Model: Claude 3 Sonnet
    
Go to console.anthropic.com
Sign up / log in
Navigate to API Keys
Create new key
Copy key (starts with `sk-ant-...`)
  </Tab>
</Tabs>

---

2. Configure API Key

Set as Supabase secret (server-side only):

```bash
For OpenAI
supabase secrets set OPENAI_API_KEY=sk-...

OR for Anthropic
supabase secrets set ANTHROPIC_API_KEY=sk-ant-...

Verify
supabase secrets list
```

<Warning>
Never expose AI API keys in frontend code! They must remain server-side only in Supabase secrets.
</Warning>

---

3. Deploy Edge Function

After setting secrets, deploy:

```bash
supabase functions deploy server
```

---

Backend Implementation

API Endpoint

The AI decomposition endpoint in `/supabase/functions/server/index.tsx`:

```typescript
app.post('/ai/decompose-task', async (c) => {
  try {
    const body = await c.req.json()
    const { taskTitle, estimatedPoints, context } = body
    
    // Validate input
    if (!taskTitle) {
      return c.json({ error: 'Task title is required' }, 400)
    }
    
    // Check for AI provider
    const openAIKey = Deno.env.get('OPENAI_API_KEY')
    const anthropicKey = Deno.env.get('ANTHROPIC_API_KEY')
    
    if (!openAIKey && !anthropicKey) {
      return c.json({ 
        error: 'AI service not configured',
        details: 'Neither OpenAI nor Anthropic API key is set'
      }, 503)
    }
    
    let subtasks: any[]
    
    // Try OpenAI first, fall back to Anthropic
    if (openAIKey) {
      subtasks = await decomposeWithOpenAI(taskTitle, estimatedPoints, context)
    } else {
      subtasks = await decomposeWithAnthropic(taskTitle, estimatedPoints, context)
    }
    
    return c.json({ subtasks })
    
  } catch (error) {
    console.error('AI decomposition error:', error)
    return c.json({ 
      error: 'Failed to generate subtasks',
      details: error.message 
    }, 500)
  }
})
```

---

OpenAI Integration

```typescript
async function decomposeWithOpenAI(
  taskTitle: string, 
  estimatedPoints: number, 
  context?: string
): Promise<any[]> {
  const apiKey = Deno.env.get('OPENAI_API_KEY')
  
  const prompt = `You are a task breakdown assistant for Task Dojo, a gamified task management app.

Break down this task into 3-5 smaller, actionable subtasks:
Task: "${taskTitle}"
Total Points: ${estimatedPoints}
${context ? `Context: ${context}` : ''}

Requirements:
3-5 subtasks maximum
Each subtask should be specific and actionable
Distribute points across subtasks (must sum to ${estimatedPoints})
Order subtasks logically
Use simple, clear language

Return ONLY a JSON array in this exact format:
[
  {"title": "Subtask 1", "points": 3, "order": 1},
  {"title": "Subtask 2", "points": 4, "order": 2},
  {"title": "Subtask 3", "points": 3, "order": 3}
]`

  const response = await fetch('https://api.openai.com/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${apiKey}`,
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({
      model: 'gpt-4-turbo-preview',
      messages: [
        { role: 'system', content: 'You are a helpful task breakdown assistant. Return only valid JSON.' },
        { role: 'user', content: prompt }
      ],
      temperature: 0.7,
      max_tokens: 500,
      response_format: { type: 'json_object' }  // Force JSON response
    })
  })
  
  if (!response.ok) {
    const error = await response.json()
    throw new Error(`OpenAI error: ${error.error?.message || 'Unknown error'}`)
  }
  
  const data = await response.json()
  const content = data.choices[0].message.content
  
  // Parse JSON response
  const parsed = JSON.parse(content)
  return parsed.subtasks || parsed  // Handle both formats
}
```

---

Anthropic Integration

```typescript
async function decomposeWithAnthropic(
  taskTitle: string, 
  estimatedPoints: number, 
  context?: string
): Promise<any[]> {
  const apiKey = Deno.env.get('ANTHROPIC_API_KEY')
  
  const prompt = `Break down this task into 3-5 smaller, actionable subtasks:
Task: "${taskTitle}"
Total Points: ${estimatedPoints}
${context ? `Context: ${context}` : ''}

Return ONLY a JSON array: [{"title": "...", "points": X, "order": 1}, ...]
Points must sum to ${estimatedPoints}.`

  const response = await fetch('https://api.anthropic.com/v1/messages', {
    method: 'POST',
    headers: {
      'x-api-key': apiKey,
      'anthropic-version': '2023-06-01',
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({
      model: 'claude-3-sonnet-20240229',
      max_tokens: 500,
      messages: [
        { role: 'user', content: prompt }
      ]
    })
  })
  
  if (!response.ok) {
    const error = await response.json()
    throw new Error(`Anthropic error: ${error.error?.message || 'Unknown error'}`)
  }
  
  const data = await response.json()
  const content = data.content[0].text
  
  // Extract JSON from response
  const jsonMatch = content.match(/\[[\s\S]*\]/)
  if (!jsonMatch) {
    throw new Error('Failed to parse Anthropic response')
  }
  
  return JSON.parse(jsonMatch[0])
}
```

---

Frontend Integration

AI Task Breakdown Component

Located in `/components/TaskBreakdown.tsx`:

```tsx
import { useState } from 'react'
import { Dialog, DialogContent } from './ui/dialog'
import { Button } from './ui/button'
import { Sparkles, Loader2 } from 'lucide-react'

export function TaskBreakdown({ taskTitle, taskPoints, open, onOpenChange, onSubtasksCreated }) {
  const [loading, setLoading] = useState(false)
  const [subtasks, setSubtasks] = useState([])
  
  const handleAIGenerate = async () => {
    setLoading(true)
    try {
      // Call AI endpoint
      const response = await fetch(
        `${import.meta.env.VITE_SUPABASE_URL}/functions/v1/make-server-4010be06/ai/decompose-task`,
        {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
            'Authorization': `Bearer ${import.meta.env.VITE_SUPABASE_ANON_KEY}`
          },
          body: JSON.stringify({
            taskTitle,
            estimatedPoints: taskPoints,
            context: 'Break this feat into 3-5 manageable steps'
          })
        }
      )
      
      if (!response.ok) {
        throw new Error('Failed to generate subtasks')
      }
      
      const data = await response.json()
      
      if (data.subtasks && data.subtasks.length > 0) {
        setSubtasks(data.subtasks)
        toast.success('Subtasks generated!')
      } else {
        throw new Error('No subtasks returned')
      }
      
    } catch (error) {
      console.error('AI generation failed:', error)
      toast.error('Failed to generate subtasks. Try manual mode.')
    } finally {
      setLoading(false)
    }
  }
  
  return (
    <Dialog open={open} onOpenChange={onOpenChange}>
      <DialogContent>
        <h2>Break Down Task</h2>
        <p>{taskTitle} ({taskPoints} points)</p>
        
        <Button onClick={handleAIGenerate} disabled={loading}>
          {loading ? (
            <>
              <Loader2 className="mr-2 h-4 w-4 animate-spin" />
              Generating...
            </>
          ) : (
            <>
              <Sparkles className="mr-2 h-4 w-4" />
              Generate with AI
            </>
          )}
        </Button>
        
        {subtasks.length > 0 && (
          <div>
            <h3>Suggested Subtasks:</h3>
            <ul>
              {subtasks.map((task, i) => (
                <li key={i}>
                  {task.title} - {task.points} points
                </li>
              ))}
            </ul>
            <Button onClick={() => onSubtasksCreated(subtasks)}>
              Create All Subtasks
            </Button>
          </div>
        )}
      </DialogContent>
    </Dialog>
  )
}
```

---

Usage Examples

Basic Task Breakdown

```typescript
// User creates a complex task
const complexTask = {
  title: 'Complete science project',
  basePoints: 50,
  category: 'academic'
}

// AI breaks it down:
const subtasks = [
  { title: 'Research topic and gather sources', points: 10, order: 1 },
  { title: 'Create project outline', points: 8, order: 2 },
  { title: 'Build experiment or model', points: 15, order: 3 },
  { title: 'Write final report', points: 12, order: 4 },
  { title: 'Prepare presentation', points: 5, order: 5 }
]
```

Custom Context

```typescript
// Provide additional context
const response = await fetch('/ai/decompose-task', {
  method: 'POST',
  body: JSON.stringify({
    taskTitle: 'Practice piano',
    estimatedPoints: 20,
    context: 'Focus on scales and technique exercises. User is a beginner.'
  })
})

// AI generates beginner-friendly subtasks
```

---

Error Handling

API Not Configured

```typescript
// Response when no API key is set
{
  error: 'AI service not configured',
  details: 'Neither OpenAI nor Anthropic API key is set'
}

// Frontend handles gracefully
if (response.status === 503) {
  toast.error('AI service unavailable. Use manual mode instead.')
  setManualMode(true)
}
```

Rate Limiting

```typescript
// OpenAI/Anthropic may rate limit
if (response.status === 429) {
  toast.error('AI service is busy. Please try again in a moment.')
  setTimeout(() => {
    // Retry after delay
    handleAIGenerate()
  }, 5000)
}
```

Fallback to Manual

```typescript
// Always provide manual option
<Button onClick={() => setManualMode(true)}>
  Add Subtasks Manually
</Button>

{manualMode && (
  <div>
    <Input 
      placeholder="Subtask title"
      value={newSubtaskTitle}
      onChange={(e) => setNewSubtaskTitle(e.target.value)}
    />
    <Button onClick={handleAddManualSubtask}>
      Add Subtask
    </Button>
  </div>
)}
```

---

Cost Management

Track Usage

```typescript
// Log AI requests for cost tracking
app.post('/ai/decompose-task', async (c) => {
  const startTime = Date.now()
  
  try {
    const subtasks = await decomposeWithOpenAI(...)
    
    // Log successful request
    console.log('AI request successful', {
      duration: Date.now() - startTime,
      provider: 'openai',
      taskTitle: body.taskTitle,
      subtasksGenerated: subtasks.length
    })
    
    return c.json({ subtasks })
  } catch (error) {
    console.error('AI request failed', {
      duration: Date.now() - startTime,
      error: error.message
    })
    throw error
  }
})
```

Set Usage Limits

```typescript
// Simple rate limiting per user
const userRequestCount = await kv.get(`ai-requests:${userId}:${today}`) || 0

if (userRequestCount >= 10) {
  return c.json({ 
    error: 'Daily AI limit reached',
    details: 'You can make 10 AI breakdowns per day'
  }, 429)
}

// Increment counter
await kv.set(`ai-requests:${userId}:${today}`, userRequestCount + 1)
```

Pricing Estimates

OpenAI GPT-4 Turbo:
Input: $0.01 per 1K tokens
Output: $0.03 per 1K tokens
Average breakdown: ~200 input + 100 output = ~$0.005

Anthropic Claude 3 Sonnet:
Input: $0.003 per 1K tokens
Output: $0.015 per 1K tokens
Average breakdown: ~200 input + 100 output = ~$0.002

Monthly costs (1000 users, 5 breakdowns/user):
OpenAI: ~$25/month
Anthropic: ~$10/month

---

Testing

Test AI Endpoint

```bash
Test with curl
curl -X POST https://your-project.supabase.co/functions/v1/make-server-4010be06/ai/decompose-task \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_ANON_KEY" \
  -d '{
    "taskTitle": "Clean bedroom",
    "estimatedPoints": 15,
    "context": "Break into simple steps"
  }'

Expected response
{
  "subtasks": [
    { "title": "Put away clothes", "points": 5, "order": 1 },
    { "title": "Organize desk", "points": 5, "order": 2 },
    { "title": "Vacuum floor", "points": 5, "order": 3 }
  ]
}
```

Mock AI Response

```typescript
// For testing without API key
if (import.meta.env.DEV && !Deno.env.get('OPENAI_API_KEY')) {
  // Return mock subtasks
  return c.json({
    subtasks: [
      { title: 'Mock subtask 1', points: Math.floor(estimatedPoints / 3), order: 1 },
      { title: 'Mock subtask 2', points: Math.floor(estimatedPoints / 3), order: 2 },
      { title: 'Mock subtask 3', points: estimatedPoints - (2 * Math.floor(estimatedPoints / 3)), order: 3 }
    ]
  })
}
```

---

Troubleshooting

API Key Not Working

Solutions:
Verify key is correct (starts with `sk-...` for OpenAI, `sk-ant-...` for Anthropic)
Check key has billing enabled
Ensure secret is set: `supabase secrets list`
Re-deploy functions: `supabase functions deploy server`

Invalid JSON Response

Solutions:
Add retry logic with exponential backoff
Improve prompt to request strict JSON format
Parse response more defensively

High Costs

Solutions:
Implement per-user rate limits
Cache common breakdowns
Use Claude instead of GPT-4 (50% cheaper)
Switch to GPT-3.5-turbo (90% cheaper, lower quality)

---

Security Best Practices

<AccordionGroup>
  <Accordion title="Never Expose API Keys" icon="lock">
    ❌ NEVER put API keys in frontend code
    
    ✅ ALWAYS keep them in Supabase secrets
    
    ✅ Call AI from server-side Edge Functions only
  </Accordion>

  <Accordion title="Validate Input" icon="shield-check">
    ```typescript
    // Sanitize user input
    const sanitized = taskTitle.trim().substring(0, 200)
    
    // Prevent prompt injection
    if (sanitized.includes('ignore previous')) {
      return c.json({ error: 'Invalid input' }, 400)
    }
    ```
  </Accordion>

  <Accordion title="Rate Limit Requests" icon="gauge">
    ```typescript
    // Prevent abuse
    const limit = await checkRateLimit(userId)
    if (!limit.allowed) {
      return c.json({ error: 'Rate limit exceeded' }, 429)
    }
    ```
  </Accordion>

  <Accordion title="Log Requests" icon="file-text">
    ```typescript
    // Monitor for unusual patterns
    console.log('AI request', {
      userId,
      taskTitle: sanitized,
      timestamp: new Date().toISOString()
    })
    ```
  </Accordion>
</AccordionGroup>

---

Next Steps

<CardGroup cols={2}>
  <Card title="Intercom Integration" icon="messages" href="/technical/integrations/intercom">
    Add customer support
  </Card>
  
  <Card title="Monitoring" icon="chart-line" href="/technical/monitoring">
    Track AI usage and errors
  </Card>
  
  <Card title="API Reference" icon="code" href="/api-reference/ai/decompose-task">
    Full API documentation
  </Card>
  
  <Card title="Cost Optimization" icon="dollar-sign" href="/technical/performance">
    Optimize AI costs
  </Card>
</CardGroup>

---

<Check>
AI integration is powerful! Use OpenAI for quality or Anthropic for cost. Always keep keys secret, validate input, and provide manual fallbacks.
</Check>
```
